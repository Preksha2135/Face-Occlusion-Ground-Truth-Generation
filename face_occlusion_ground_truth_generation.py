# -*- coding: utf-8 -*-
"""DeepLab_for_ground_truth_image_generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lsYfe1VEaSsv5SdG1k_soTavCeoTDw3X
"""

import torch
import torchvision
from torchvision import transforms, models
from torch.utils.data import DataLoader, Dataset
import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# Custom Dataset
class OcclusionDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform

        # Only include valid files (no directories or hidden files)
        self.images = sorted([f for f in os.listdir(image_dir) if f.endswith(('jpg', 'png', 'jpeg'))])
        self.masks = sorted([f for f in os.listdir(mask_dir) if f.endswith(('jpg', 'png', 'jpeg'))])

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_dir, self.images[idx])
        mask_path = os.path.join(self.mask_dir, self.masks[idx])

        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")  # Grayscale mask

        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)

        return image, mask

# Data augmentation for images
image_transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor()
])

# Mask transform (no normalization)
mask_transform = transforms.Compose([
    transforms.Resize((256, 256), interpolation=Image.NEAREST),
    transforms.Lambda(lambda x: torch.from_numpy(np.array(x, dtype=np.int64)))
])

# Paths to Dataset
train_image_dir = "assets/1"
train_mask_dir = "assets/GroundTruth"
test_image_dir = "assets/2"

# Create Datasets and Loaders
train_dataset = OcclusionDataset(
    train_image_dir,
    train_mask_dir,
    transform=image_transform,
    # mask_transform=mask_transform
)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

# Load Pretrained DeepLabV3+ Model
model = models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True, output_stride=8)
model.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=1)  # Adjust for 2 classes (occlusion and non-occlusion)
model = model.to("cuda" if torch.cuda.is_available() else "cpu")

# Define Loss and Optimizer
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Training Loop
num_epochs = 50
device = "cuda" if torch.cuda.is_available() else "cpu"

for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.squeeze(1).to(device, dtype=torch.long)  # Remove the channel dimension and convert to Long

        optimizer.zero_grad()
        outputs = model(images)["out"]
        loss = criterion(outputs, masks)  # Compute loss
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()


    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

transform = transforms.Compose([
    transforms.Resize((256, 256)),  # Ensure consistent input size
    transforms.ToTensor()
])

# Inference on New Images
device = "cuda" if torch.cuda.is_available() else "cpu"
def predict(image_path, model, transform, device):
    model.eval()

    image = Image.open(image_path).convert("RGB")
    input_image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(input_image)["out"]
        mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

    return mask

# Visualize Results
# test_image_path = "/content/drive/MyDrive/Colab Notebooks/Face occlusion resources/2/62_surgical.jpg"
# predicted_mask = predict(test_image_path, model, transform)

# plt.figure(figsize=(10, 5))
# plt.subplot(1, 2, 1)
# plt.title("Input Image")
# plt.imshow(Image.open(test_image_path))
# plt.axis("off")

# plt.subplot(1, 2, 2)
# plt.title("Predicted Mask")
# plt.imshow(predicted_mask, cmap="gray")
# plt.axis("off")

# plt.show()

# Function to process an entire folder of images

def generate_masks_for_nested_folders(input_folder, output_folder, model, transform):
    """
    Generate predicted masks for images in a folder and its subfolders, and save them in the output folder.

    Args:
        input_folder (str): Path to the folder containing input images and/or subfolders.
        output_folder (str): Path to the folder where masks will be stored (same structure as input_folder).
        model (torch.nn.Module): Trained segmentation model.
        transform (torchvision.transforms.Compose): Transform for preprocessing images.
    """
    os.makedirs(output_folder, exist_ok=True)
    device = "cuda" if torch.cuda.is_available() else "cpu"

    for root, _, files in os.walk(input_folder):  # Recursively walk through all directories
        relative_path = os.path.relpath(root, input_folder)  # Maintain relative folder structure
        current_output_folder = os.path.join(output_folder, relative_path)
        os.makedirs(current_output_folder, exist_ok=True)  # Create subfolder in output if necessary

        for file in files:
            if not file.lower().endswith(('jpg', 'jpeg', 'png')):
                continue  # Skip non-image files

            image_path = os.path.join(root, file)
            print(f"Processing: {image_path}")

            # Predict mask
            mask = predict(image_path, model, transform, device)

            # Save the predicted mask
            mask_image = Image.fromarray((mask * 255).astype('uint8'))  # Scale mask values to 0-255
            output_path = os.path.join(current_output_folder, f"{os.path.splitext(file)[0]}_mask.png")
            mask_image.save(output_path)

    print(f"Mask generation complete. Masks saved to {output_folder}")

# Paths
input_folder = "/content/drive/MyDrive/Colab Notebooks/Face occlusion resources/OccludedImages(mini)"  # Folder containing nested folders with images
output_folder = "/content/drive/MyDrive/Colab Notebooks/Face occlusion resources/Generated ground truth images"           # Folder to save generated masks

# Generate masks for all images in the folder and its subfolders
generate_masks_for_nested_folders(input_folder, output_folder, model, transform)

